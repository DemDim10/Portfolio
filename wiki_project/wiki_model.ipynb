{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in /Users/DMITRYD/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: requests in /Users/DMITRYD/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from pymystem3) (2.27.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/DMITRYD/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->pymystem3) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/DMITRYD/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->pymystem3) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/DMITRYD/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->pymystem3) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/DMITRYD/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->pymystem3) (3.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/DMITRYD/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/DMITRYD/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159287    \":::::And for the second time of asking, when ...\n",
       "159288    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159289    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159290    And it looks like it was actually you who put ...\n",
       "159291    \"\\nAnd ... I really don't think you understand...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим текст от ненужных символов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [explanation, why, the, edits, made, under, my...\n",
       "1    [daww, he, matches, this, background, colour, ...\n",
       "2    [hey, man, im, really, not, trying, to, edit, ...\n",
       "3    [more, i, cant, make, any, real, suggestions, ...\n",
       "4    [you, sir, are, my, hero, any, chance, you, re...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text)\n",
    "    text = text.lower()\n",
    "    return text.split()\n",
    "\n",
    "df['text'] = df['text'].apply(cleaning)\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем лемматизацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    daww he match this background colour im seemin...\n",
       "2    hey man im really not trying to edit war it ju...\n",
       "3    more i cant make any real suggestion on improv...\n",
       "4    you sir are my hero any chance you remember wh...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "corpus = df['text']\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lem = [wnl.lemmatize(word) for word in text]\n",
    "    return ' '.join(lem)\n",
    "\n",
    "\n",
    "corpus = corpus.apply(lemmatizer)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст обработан. Можем переходить к обучению. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic'][0 : 160000].values\n",
    "features = corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем признаки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии и подберем параметры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters is: {'model': LogisticRegression(C=4, penalty='l1', random_state=12345, solver='liblinear'), 'model__C': 4, 'model__penalty': 'l1'}\n",
      "Best score is: 0.7580108185706296\n",
      "CPU times: user 2.83 s, sys: 356 ms, total: 3.19 s\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    " ('tfidf',  TfidfTransformer()),\n",
    " ('model', LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "        {\n",
    "\n",
    "            'model': [LogisticRegression(random_state=12345, solver='liblinear')],\n",
    "            'model__penalty' : ['l1', 'l2'],\n",
    "            'model__C': list(range(1,15,3))\n",
    "        }\n",
    "]\n",
    "grid = GridSearchCV(pipe_lr, param_grid=param_grid, scoring='f1', cv=3, verbose=True, n_jobs=-1)\n",
    "best_grid = grid.fit(tf_idf, target)\n",
    "print('Best parameters is:', grid.best_params_)\n",
    "print('Best score is:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем то же самое для случайного леса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\nparams_forest = {\\n    'n_estimators': list(range(50, 300, 50)),\\n    'max_depth':[5, 30],\\n    'max_features' : list(range(10, 100, 10))\\n}\\n\\n\\nmodel_forest = RandomForestClassifier(random_state=12345)\\n                                 \\ngrid = GridSearchCV(model_forest, param_grid=params_forest, scoring='f1', cv=3, verbose=True, n_jobs=-1)\\nbest_grid = grid.fit(tf_idf, target)\\nprint('Best parameters is:', grid.best_params_)\\nprint('Best score is:', grid.best_score_)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params_forest = {\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    'max_depth':[5, 30],\n",
    "    'max_features' : list(range(10, 100, 10))\n",
    "}\n",
    "\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=12345)\n",
    "                                 \n",
    "grid = GridSearchCV(model_forest, param_grid=params_forest, scoring='f1', cv=3, verbose=True, n_jobs=-1)\n",
    "best_grid = grid.fit(tf_idf, target)\n",
    "print('Best parameters is:', grid.best_params_)\n",
    "print('Best score is:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707162323098605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, C = 4, penalty = 'l1', solver='liblinear')\n",
    "model.fit(tf_idf, target)\n",
    "valid_pred = model.predict(tf_idf)\n",
    "f1 = cross_val_score(\n",
    "        model, tf_idf, target, scoring=\"f1\", cv=3\n",
    "    ).mean()\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(max_depth=5, max_features=10, n_estimators = 50)\n",
    "model_forest.fit(tf_idf, target)\n",
    "valid_pred_f = model_forest.predict(tf_idf)\n",
    "f1 = cross_val_score(\n",
    "        model_forest, tf_idf, target, scoring=\"f1\", cv=3\n",
    "    ).mean()\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработали и подготовили данные, обучили разные модели с подбором гиперпараметров и на тестовой выборке получили значение f1 метрики **0.77**, использовав логистическую регрессию.  "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1438,
    "start_time": "2022-09-05T19:52:29.815Z"
   },
   {
    "duration": 219,
    "start_time": "2022-09-05T19:56:00.704Z"
   },
   {
    "duration": 103,
    "start_time": "2022-09-05T19:56:51.982Z"
   },
   {
    "duration": 82,
    "start_time": "2022-09-05T19:57:04.379Z"
   },
   {
    "duration": 1933,
    "start_time": "2022-09-05T19:57:20.715Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-05T19:57:22.650Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-05T19:57:22.658Z"
   },
   {
    "duration": 87,
    "start_time": "2022-09-05T19:57:22.672Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.762Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.763Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.765Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.766Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.767Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.769Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.770Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.771Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.772Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.773Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.774Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-05T19:57:22.775Z"
   },
   {
    "duration": 44,
    "start_time": "2022-09-07T19:45:46.732Z"
   },
   {
    "duration": 2243,
    "start_time": "2022-09-07T19:45:52.010Z"
   },
   {
    "duration": 1063,
    "start_time": "2022-09-07T19:45:54.256Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-07T19:45:55.321Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-07T19:45:55.322Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-07T19:45:55.323Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-07T19:45:55.324Z"
   },
   {
    "duration": 46,
    "start_time": "2022-09-09T10:59:11.507Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
